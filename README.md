**Welcome – A Data-Driven Journey into Public Policy**
*Exploring how data analytics can transform political science*

Hello and welcome to this project.
This repository holds a piece of work that is especially meaningful to me—not only because it is my undergraduate thesis, but because it represents a deep conviction I have developed throughout my studies: data analytics has enormous potential to enrich political science and the social sciences more broadly.

This project is the result of saying yes to a new methodological path emerging within the discipline the agnostic approach. A path that encourages us to explore the massive amount of data available today and use it to better understand complex social phenomena. It is also the result of countless hours of self-learning, experimenting with tools, making mistakes, and discovering new ways to analyze public policy problems through exploration and curiosity.

This web interface and analytical process reflect my desire to build a bridge between political theory and computational analysis—between what we assume about public problems and what the data can reveal about them.

**About This Project**
This work is structured around two main components that together tell the full story:

**1. A Web Interface Built from Scratch**

The project includes a functional web interface designed to present, in an intuitive and didactic way, the entire analytical process behind examining the Theory of Change of Medellín’s 2024–2027 Public Safety and Coexistence Policy.

I built this interface using:

HTML for the page structure

CSS for styling and design

JavaScript for interactivity and logic

My goal was to create a digital space where any reader—student, policymaker, or researcher—can explore the methodological journey in a clear and accessible way.

This page is the product of self-directed learning and represents my first step into frontend development, motivated purely by the desire to make my research more open, transparent, and engaging.

**2. The Data Analysis Behind the Project**

The analytical backbone of the project follows the well-known OSEMN methodology, which guided the full cycle:

Obtain – identifying and collecting data

Scrub – cleaning, correcting, and preparing the dataset

Explore – searching for patterns and key features

Model – applying statistical and machine learning techniques

Narrate – interpreting and communicating insights

This process is inspired by the agnostic approach proposed by Grimmer (2021), a leading scholar in data science for political science.
This approach encourages us to let the data speak first, allowing empirical behavior to refine or even challenge theoretical assumptions.

To carry out the analysis, I worked with:

Excel for initial structuring, Python for cleaning, transforming, and modeling the data

Analytical methods such as:

Clustering, PCA, Random Forest, Linear sequences / time-based patterns, Heatmaps and correlation matrices

Key libraries included pandas, numpy, matplotlib, seaborn, and scikit-learn.

This analytical path reflects not only technical work, but also a learning journey—understanding how to translate political questions into data problems and how to interpret computational results through a public policy lens.

**How the Website Works**
The platform is designed to guide you step-by-step through the research process. You can see all codes of the structure in **docs** above here, also you can find the codes used for the analysis in the field called **"Analysis"** 

**1. Landing Page**

The first interface introduces:

The motivation for the project, The theoretical foundation, The problem being analyzed, The role of the agnostic, data-driven lens

It sets the stage for everything that follows.

**2. Navigation Buttons**

You will find three main buttons:

Top-left: links to the official technical document approved by my faculty committee

Top-right: links to the repository containing the full HTML/CSS/JS codebase

Bottom button: takes you directly to the analytical phases

This design makes it easy to navigate between the academic document, the code, and the methodological journey.

**3. Analytical Pathway**

The second page organizes the methodological process into four moments—from initial identification to conclusions—mirroring the actual workflow of the research.

**4. Detailed Analytical Sections**

Each page then presents:

A summary of the previous steps, The purpose of the current stage, Explanations of techniques applied, Visualizations, Python code, and interpretations

For example, the analysis page showcases:

Heatmaps, PCA projections, Clustering outcomes, Random Forest variable importance, Time-based behavior of indicators

This allows anyone visiting the page to trace each decision and see how the analysis unfolds.

**Final Thoughts**

This repository is not just a collection of files.
It is a journey—one shaped by curiosity, experimentation, and the belief that political science thrives when it embraces data.

I hope this project inspires other students and young researchers to explore quantitative approaches, experiment with code, and trust in their ability to adapt to new analytical environments.

If you have feedback, ideas, or simply want to talk about data in political science, feel free to reach out.
