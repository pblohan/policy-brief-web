<!DOCTYPE html>
<html lang="es">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Primer √ânfasis - Identificaci√≥n</title>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="enfasis_identificacion.css">
</head>
<body>
    <div class="page-background"></div>
    
    <header class="header">
        <div class="header-text">Trabajo de grado</div>
    </header>

    <nav class="nav-bar">
        <a href="../../index.html">üè† Inicio</a>
        <a href="../lobby.html">‚Ü© Volver</a>
        <a href="../enfasis_procesamiento/enfasis_procesamiento.html">Siguiente: √©nfasis ‚û°Ô∏è</a>
        <a href="https://docs.google.com/spreadsheets/d/1KPaJCxspWTzdCLBKmS-kBVEGlHSXS71x/edit?gid=2115816323#gid=2115816323" target="_blank" class="spreadsheet-button">üìä Ver Base de Datos</a>
        <a href="https://colab.research.google.com/drive/1UlphS8nWJBqdwYFKnR7aqNHvjfyqWPdP?usp=sharing" target="_blank" class="spreadsheet-button">üóÉÔ∏èC√≥digos usados</a>
    </nav>

    <div class="container">
        <section class="explanation-section">
            <h1>Primer √ânfasis: B√∫squeda de datos como punto de partida</h1>
            <div class="content">
                <p class="emphasis-description">
                    El primer proceso de anal√≠tica de datos es la identificaci√≥n del problema a estudiar. Desde el inicio del proceso, el objetivo fundamental del trabajo fue  analizar la expresi√≥n de un problema de car√°cter social a trav√©s del an√°lisis de datos. En un primer momento, no se ten√≠a una definici√≥n exacta del problema a estudiar, por lo que el enfoque inicial fue la b√∫squeda de una base de datos que sirviera como principal fuente de an√°lisis para usarse en la reproducci√≥n del comportamiento de los datos.</p>

                    <p class="emphasis-description">  Para ello, se explor√≥ la t√©cnica de scraping como una posible herramienta √∫til para la gesti√≥n y extracci√≥n de bases de datos de diferentes fuentes en la web.
                    <div class="card">
                        <div class="header">
                          <div class="top">
                            <div class="circle">
                              <span class="red circle2"></span>
                            </div>
                            <div class="circle">
                              <span class="yellow circle2"></span>
                            </div>
                            <div class="circle">
                              <span class="green circle2"></span>
                            </div>
                            <div class="title">
                              <p id="title2">modelo de c√≥digo scraping utilizado</p>
                            </div>
                          </div>
                        </div>
                        <div class="code-container">
                          <textarea class="area" id="code" name="code" readonly="">
                            from bs4 import BeautifulSoup
                            import requests
                            import os
                            from urllib.parse import urljoin
                            
                            def scrape_download_links(url):
                                # Realizar la solicitud GET a la p√°gina
                                response = requests.get(url)
                                
                                # Verificar si la solicitud fue exitosa (c√≥digo de estado 200)
                                if response.status_code == 200:
                                    # Obtener el contenido HTML de la p√°gina
                                    html = response.text
                                    
                                    # Crear un objeto BeautifulSoup para analizar el HTML
                                    soup = BeautifulSoup(html, 'html.parser')
                                    
                                    # Encontrar todos los elementos <a> que representan enlaces
                                    links = soup.find_all('a')
                                    
                                    # Lista para almacenar las URLs de descarga
                                    download_links = []
                                    
                                    # Iterar sobre los enlaces encontrados
                                    for link in links:
                                        # Obtener la URL del enlace
                                        url_enlace = link.get('href')
                                        
                                        # Verificar si la URL apunta a un archivo Excel (.xls, .xlsx)
                                        if url_enlace.endswith('.xls') or                                                                     url_enlace.endswith('.xlsx'):
                                            # Crear una URL absoluta uniendo el dominio con la URL                                                 del enlace
                                            url_absoluta = urljoin(url, url_enlace)
                                            
                                            # Agregar la URL a la lista de URLs de descarga
                                            download_links.append(url_absoluta)
                                    
                                    # Descargar y guardar los archivos
                                    for download_link in download_links:
                                        # Realizar la solicitud GET al archivo
                                        file_response = requests.get(download_link)
                                        
                                        # Verificar si la solicitud fue exitosa (c√≥digo de estado 200)
                                        if file_response.status_code == 200:
                                            # Obtener el nombre del archivo de la URL
                                            filename = os.path.join('C:\\Users\\DIVAR                                                          RESTREPO\\OneDrive\\Escritorio\\formato excel',                                                       download_link.split('/')[-1])
                                            
                                            # Guardar el archivo en el sistema local
                                            with open(filename, 'wb') as file:
                                                file.write(file_response.content)
                                    
                                    print("Se han descargado y guardado los archivos de Excel en                                           'C:\\Users\\DIVAR RESTREPO\\OneDrive\\Escritorio\\formato                                             excel'")
                                        else:
                                        print("Error al acceder a la p√°gina:", response.status_code)
                            
                                        # URL de la p√°gina que contiene los enlaces de descarga
                                       url_pagina = 'https://upom.chapingo.mx/base-de-datos-en-excel/'
                            
                                        # Llamar a la funci√≥n para recopilar las URLs de descarga
                                        scrape_download_links(url_pagina)
                      }</textarea>
                        </div>
                      </div>
                      <p class="emphasis-description">El scraping, en t√©rminos generales, es una t√©cnica que permite consultar datos alojados en un servidor web y extraerlos desde el c√≥digo de la p√°gina para almacenarlos en un ordenador. En este caso, se desarroll√≥ un c√≥digo en Python  utilizando las bibliotecas BeautifulSoup y Requests, con el prop√≥sito de descargar bases de datos en formato .xlsx desde sitios web espec√≠ficos.
                        Este c√≥digo permite ubicar una base de datos en la web, descargarla y guardarla en una carpeta espec√≠fica del ordenador. El c√≥digo se centra en buscar enlaces de descarga de archivos Excel (.xls, .xlsx) a trav√©s del rastreo de c√≥digo HTML que estructura la p√°gina web y luego descargar esos archivos a una ubicaci√≥n local.</p>
            </div>
        </section>

        <section class="explanation-section">
            <div class="content">
                <div class="data-table">
                    <div class="table-title">Resultados de b√∫squeda de bases de datos</div>
                    <div class="table-content">
                        <div class="table-header">
                            <div class="column">Fuente</div>
                            <div class="column">Tipo de datos</div>
                            <div class="column">Accesibilidad</div>
                            
                        </div>
                        <div class="table-row">
                            <div class="column">Datos Abiertos Colombia</div>
                            <div class="column">Seguridad ciudadana/gubernamental</div>
                            <div class="column">Plataforma oficial de datos abiertos. Muchas bases requieren APIs.</div>
                            
                        </div>
                        <div class="table-row">
                            <div class="column">DANE</div>
                            <div class="column">Estad√≠sticas vitales/institucional</div>
                            <div class="column">Acceso a microdatos requiere registro. Muchas bases se ofrecen v√≠a API.</div>
                        </div>
                        <div class="table-row">
                            <div class="column">MEData (Medell√≠n C√≥mo Vamos)</div>
                            <div class="column">Delitos/gubernamental</div>
                            <div class="column">Plataforma oficial de datos abiertos. Muchas bases requieren APIs.</div>
                        </div>
                        <div class="table-row">
                            <div class="column">SISPRO (Sistema Integral de Informaci√≥n de la Protecci√≥n Social)</div>
                            <div class="column">Salud p√∫blica/Gubernamental</div>
                            <div class="column">Acceso restringido; requiere navegaci√≥n avanzada.</div>
                        </div>
                        <div class="table-row">
                            <div class="column">SIMAT (Sistema Integrado de Matr√≠cula)</div>
                            <div class="column">Gubernamental </div>
                            <div class="column">Datos m√°s restringidos o no en formato amigable.API requerida</div>
                        </div>
                        <div class="table-row">
                            <div class="column">SUI (Sistema √önico de Informaci√≥n - Superservicios)</div>
                            <div class="column">Ofrece datos de servicios p√∫blicos/Gubernamental</div>
                            <div class="column">Acceso restringido</div>
                        </div>
                        <div class="table-row">
                            <div class="column">Banco de la Rep√∫blica - Estad√≠sticas</div>
                            <div class="column">Datos econ√≥micos/Institucional</div>
                            <div class="column">API requerida</div>
                        </div>
                        <div class="table-row">
                            <div class="column">Geoportal IGAC</div>
                            <div class="column">Datos geogr√°ficos/institucional</div>
                            <div class="column">Dif√≠ciles de scrapear por estructura no HTML.</div>
                        </div>
                        <div class="table-row">
                            <div class="column">Observatorio de Seguridad Ciudadana de Medell√≠n</div>
                            <div class="column">Datos valiosos sobre seguridad/ gubernamental</div>
                            <div class="column">Algunos en PDF o formatos no estructurados.API requerida</div>
                        </div>
                        <div class="table-row">
                            <div class="column">DNP</div>
                            <div class="column">Desarrollo nacional</div>
                            <div class="column">Acceso restringido</div>
                        </div>
                    </div>
                </div>
                <p class="emphasis-description"> Se puso a prueba el c√≥digo en un total de diez p√°ginas web de distintos tipos (gubernamentales, institucionales, corporativas, entre otras), el foco estaba puesto en bases de datos que tuviesen integradas categor√≠as referentes a la seguridad por recomendaci√≥n del tutor dada la producci√≥n cient√≠fica que existe del sector. Sin embargo, el principal problema encontrado fue que muchas de las bases de datos abiertas no tienen una estructura HTML accesible de manera directa, sino que requieren el uso de APIs para su consulta. Esto implica un nivel de conocimiento avanzado en la t√©cnica de scraping que el c√≥digo desarrollado no soporta. Adem√°s, la disponibilidad de bases de datos abiertas result√≥ ser limitada, por lo que no hubo acceso a una amplia gama de vol√∫menes de datos.</p>
            </div>
        </section>

        <section class="collision-points">
            <h2>Puntos de Choque</h2>
            <div class="collision-grid">
                <div class="collision-item">
                    <span class="collision-icon">‚ùå</span>
                    <p>Durante el proceso inicial, se intent√≥ construir una base de datos propia aplicando t√©cnicas de scraping para extraer informaci√≥n de distintas plataformas. Sin embargo, fue evidente que muchas de estas p√°ginas no permiten un acceso sencillo a los datos, ya sea porque requieren el uso de APIs o porque su estructura no es compatible con herramientas b√°sicas de recolecci√≥n. Esta dificultad, sirvi√≥ como punto de quiebre para redirigir el enfoque metodol√≥gico.</p>
                </div>
            </div>
        </section>

        <section class="key-points">
            <h2>Puntos Clave del √ânfasis</h2>
            <div class="key-points-grid">
                <div class="key-point">
                    <span class="key-icon">üîë</span>
                    <h3>Punto Clave </h3>
                    <p>En lugar de insistir en extraer informaci√≥n dispersa y de dif√≠cil acceso, se opt√≥ por trabajar con una base de datos ya consolidada y confiable. Esta decisi√≥n permiti√≥ concentrar esfuerzos en el an√°lisis mismo, y no en la construcci√≥n de la base, lo cual tambi√©n facilit√≥ avanzar hacia una organizaci√≥n m√°s clara de las variables y, poco a poco, hacia la delimitaci√≥n del fen√≥meno que a√∫n se estaba definiendo.</p>
                </div>
            </div>
        </section>

        <section class="key-points">
            <div class="key-points-grid">
                <div class="key-point1">
            <p class="emphasis-description">Para una descripci√≥n m√°s detallada de este primer √©nfasis, se recomienda consultar las p√°ginas 24 a 27 de la memoria metodol√≥gica.</p>
              <a href="https://drive.google.com/file/d/1wSvdfORgIifqX8BVCmRf6fSkCUEuZeQZ/view?usp=sharing" target="_blank" class="spreadsheet-button"  id="page19">memoria metodol√≥gica</a>
              </div>  
            </div>
        </section>

    </div>

    <footer>
        <div class="footer-title">Universidad de Antioquia</div>
        <p>M√°s informaci√≥n: pablo.restrepo3@udea.edu.co</p>
    </footer>

      <script src="enfasis_identificacion.js"></script>
</body>
</html>